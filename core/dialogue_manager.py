# dialogue_manager.py
"""
çœŸæ­£çš„LLMé©±åŠ¨å¯¹è¯ç®¡ç†å™¨
ä½¿ç”¨LLMç”Ÿæˆè‡ªç„¶è¡”æ¥ï¼Œè€Œä¸æ˜¯å›ºå®šæ¨¡æ¿
"""
import time
import json
import logging
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime


logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger("dialogue_manager")

class SmartDialogueManager:
    """æ™ºèƒ½å¯¹è¯ç®¡ç†å™¨ - çœŸæ­£ä½¿ç”¨LLMç”Ÿæˆè‡ªç„¶è¡”æ¥"""
    def __init__(self, llm_client=None):
        self.llm_client = llm_client
        self.conversation_history = []  # å®Œæ•´çš„å¯¹è¯å†å²
        self.components_history = []  # è®²è§£è¿‡çš„éƒ¨ä»¶å†å²
        self.max_history = 8  # æœ€å¤šè®°ä½8ä¸ªéƒ¨ä»¶

        logger.info("ğŸ¤– æ™ºèƒ½å¯¹è¯ç®¡ç†å™¨å·²åˆå§‹åŒ–")
        if llm_client:
            logger.info("âœ… LLMå®¢æˆ·ç«¯å·²è¿æ¥")

    # ================== æ ¸å¿ƒæ–¹æ³•ï¼šLLMç”Ÿæˆè¡”æ¥ ==================

    async def generate_intelligent_transition(self, new_component: Dict[str, Any],
                                              target_language: str = "zh-CN") -> Tuple[str, str]:
        """
        ä½¿ç”¨LLMæ™ºèƒ½ç”Ÿæˆè¡”æ¥å’Œè®²è§£

        Args:
            new_component: æ–°éƒ¨ä»¶ä¿¡æ¯
            target_language: ç›®æ ‡è¯­è¨€

        Returns:
            (transition_text, full_narrative) - è¡”æ¥æ–‡æœ¬å’Œå®Œæ•´è®²è§£
        """
        component_name = new_component.get('label', '')
        component_desc = new_component.get('description', '')

        # 1. æ„å»ºLLMæç¤ºè¯ï¼ˆå…³é”®ï¼ï¼‰
        prompt = self._build_intelligent_prompt(
            component_name=component_name,
            component_description=component_desc,
            conversation_history=self.conversation_history,
            target_language=target_language
        )

        logger.info(f"ğŸ§  ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½è¡”æ¥ - è¯­è¨€: {target_language}")

        try:
            # 2. è°ƒç”¨LLMç”Ÿæˆè‡ªç„¶è¡”æ¥çš„è®²è§£
            llm_response = await self.llm_client.generate_summary(
                context=prompt,
                target_language=target_language,
                question=None  # æ‚¨çš„llm_clientå¯èƒ½éœ€è¦è¿™ä¸ªå‚æ•°
            )

            # 3. è§£æLLMå“åº”ï¼ˆå¯èƒ½åŒ…å«è¡”æ¥å’Œè®²è§£ï¼‰
            transition, narrative = self._parse_llm_response(
                llm_response, component_name, target_language
            )

            logger.info(f"âœ… LLMç”Ÿæˆå®Œæˆ - è¡”æ¥é•¿åº¦: {len(transition)} å­—ç¬¦")

            return transition, narrative

        except Exception as e:
            logger.error(f"LLMç”Ÿæˆå¤±è´¥: {e}")
            # å›é€€åˆ°ç®€å•è¡”æ¥
            return self._generate_fallback_transition(component_name), component_desc

    def _build_intelligent_prompt(self, component_name: str, component_description: str,
                                  conversation_history: List, target_language: str) -> str:
        """
        æ„å»ºæ™ºèƒ½æç¤ºè¯ï¼Œè®©LLMç†è§£ä¸Šä¸‹æ–‡å¹¶ç”Ÿæˆè‡ªç„¶è¡”æ¥

        è¿™æ˜¯å…³é”®ï¼ä¸æ˜¯å›ºå®šæ¨¡æ¿ï¼Œè€Œæ˜¯è®©LLMç†è§£æ•´ä¸ªå¯¹è¯
        """
        # 1. æå–å†å²ä¿¡æ¯
        history_text = self._format_conversation_history(conversation_history)

        # 2. æ„å»ºæç¤ºè¯ï¼ˆæ ¹æ®ä¸åŒè¯­è¨€è°ƒæ•´ï¼‰
        if target_language == "zh-CN":
            prompt = f"""ä½ æ˜¯ä¸€åä¸“ä¸šçš„æ±½è½¦é”€å”®é¡¾é—®ï¼Œæ­£åœ¨ç›´æ’­ä»‹ç»è½¦è¾†ã€‚

## å¯¹è¯å†å²å›é¡¾ï¼š
{history_text if history_text else "è¿™æ˜¯ç¬¬ä¸€æ¬¡ä»‹ç»è½¦è¾†ã€‚"}

## ç°åœ¨è¦ä»‹ç»çš„æ–°éƒ¨ä»¶ï¼š
**{component_name}**

## è¿™ä¸ªéƒ¨ä»¶çš„æŠ€æœ¯ä¿¡æ¯ï¼š
{component_description}

## ä½ çš„ä»»åŠ¡ï¼š
è¯·ç”Ÿæˆä¸€æ®µè‡ªç„¶æµç•…çš„ç›´æ’­é”€å”®è®²è§£ï¼Œè¦æ±‚ï¼š

1. **è¡”æ¥è‡ªç„¶**ï¼šå¦‚æœä¹‹å‰ä»‹ç»è¿‡å…¶ä»–éƒ¨ä»¶ï¼Œè¯·è‡ªç„¶åœ°ä»è¿™ä¸ªè¯é¢˜è¿‡æ¸¡åˆ°æ–°éƒ¨ä»¶
2. **çªå‡ºäº®ç‚¹**ï¼šç”¨ç”ŸåŠ¨æœ‰è¶£çš„æ–¹å¼ä»‹ç»è¿™ä¸ªéƒ¨ä»¶çš„ä¼˜ç‚¹
3. **è¯­è¨€é£æ ¼**ï¼šåƒæœ‹å‹èŠå¤©ä¸€æ ·è‡ªç„¶ï¼Œæœ‰ç›´æ’­çš„æ„ŸæŸ“åŠ›
4. **ç»“æ„å»ºè®®**ï¼š
   - å¼€åœºè¡”æ¥ï¼ˆå¦‚æœä¹‹å‰æœ‰å†…å®¹ï¼‰
   - éƒ¨ä»¶ä»‹ç»ï¼ˆçªå‡º1-2ä¸ªæ ¸å¿ƒä¼˜ç‚¹ï¼‰
   - ç»“æŸè¿‡æ¸¡ï¼ˆä¸ºä¸‹ä¸€æ­¥ç•™æœ‰ä½™åœ°ï¼‰

è®°ä½ï¼šä½ ä¸æ˜¯åœ¨è¯»è¯´æ˜ä¹¦ï¼Œè€Œæ˜¯åœ¨å’Œæœ‹å‹åˆ†äº«å¥½ä¸œè¥¿ï¼

è¯·å¼€å§‹ä½ çš„è®²è§£ï¼š"""

        elif target_language == "en-US":
            prompt = f"""You are a professional car sales consultant doing a live stream.

## Conversation History:
{history_text if history_text else "This is the first introduction to the vehicle."}

## New component to introduce:
**{component_name}**

## Technical information about this component:
{component_description}

## Your task:
Generate a natural, engaging live stream sales pitch:

1. **Smooth transition**: If you've introduced other components before, naturally transition to this new one
2. **Highlight benefits**: Focus on 1-2 key benefits in an engaging way
3. **Language style**: Conversational, friendly, like sharing with friends
4. **Suggested structure**:
   - Opening transition (if applicable)
   - Component introduction
   - Closing transition

Remember: You're not reading a manual, you're sharing something cool with friends!

Start your pitch:"""

        else:
            # å…¶ä»–è¯­è¨€çš„é€šç”¨æç¤ºè¯
            prompt = f"""You are introducing car components in a live stream.

History: {history_text}
New component: {component_name}
Info: {component_description}

Please introduce this component naturally, connecting it to previous topics if any."""

        return prompt

    def _format_conversation_history(self, history: List) -> str:
        """æ ¼å¼åŒ–å¯¹è¯å†å²"""
        if not history:
            return ""

        # åªå–æœ€è¿‘3æ¬¡è®²è§£
        recent = history[-3:] if len(history) > 3 else history

        formatted = []
        for i, entry in enumerate(recent):
            # æå–å…³é”®ä¿¡æ¯
            component = entry.get('component', '')
            narrative = entry.get('narrative', '')

            # åªå–å‰100ä¸ªå­—ç¬¦
            preview = narrative[:100] + "..." if len(narrative) > 100 else narrative

            formatted.append(f"{i + 1}. {component}: {preview}")

        return "\n".join(formatted)

    def _parse_llm_response(self, llm_response: str, component_name: str,
                            target_language: str) -> Tuple[str, str]:
        """
        è§£æLLMå“åº”ï¼Œæå–è¡”æ¥éƒ¨åˆ†å’Œå®Œæ•´è®²è§£

        ç­–ç•¥ï¼šå¦‚æœLLMå“åº”å¾ˆé•¿ï¼Œæ™ºèƒ½åˆ†å‰²å‡ºè¡”æ¥éƒ¨åˆ†
        """
        # æ¸…ç†å“åº”
        response = llm_response.strip()

        # å¯¹äºä¸­æ–‡ï¼Œå°è¯•æ‰¾è‡ªç„¶çš„åˆ†å‰²ç‚¹
        if target_language == "zh-CN":
            # å¸¸è§çš„ä¸­æ–‡è¡”æ¥è¯ä½ç½®
            transition_markers = ["æ¥ä¸‹æ¥", "æˆ‘ä»¬å†çœ‹", "é™¤äº†", "å¦å¤–", "åŒæ—¶", "è¯´åˆ°"]

            for marker in transition_markers:
                if marker in response[:50]:  # åœ¨å‰50ä¸ªå­—ç¬¦å†…æ‰¾
                    # æ‰¾åˆ°è¡”æ¥è¯çš„ç»“æŸä½ç½®ï¼ˆé€šå¸¸åˆ°ç¬¬ä¸€ä¸ªå¥å·ï¼‰
                    end_pos = response.find("ã€‚", response.find(marker))
                    if end_pos > 0:
                        transition = response[:end_pos + 1]
                        narrative = response
                        return transition, narrative

        # é»˜è®¤ï¼šå‰1-2å¥ä½œä¸ºè¡”æ¥
        sentences = self._split_sentences(response, target_language)

        if len(sentences) >= 2:
            # å‰1-2å¥ä½œä¸ºè¡”æ¥
            transition = "".join(sentences[:2])
            narrative = response
        else:
            # åªæœ‰ä¸€å¥ï¼Œæ•´ä¸ªä½œä¸ºè®²è§£
            transition = f"æˆ‘ä»¬æ¥çœ‹çœ‹{component_name}ï¼Œ"
            narrative = response

        return transition, narrative

    def _split_sentences(self, text: str, language: str) -> List[str]:
        """æŒ‰è¯­è¨€åˆ†å¥"""
        if language == "zh-CN":
            # ä¸­æ–‡åˆ†å¥
            import re
            sentences = re.split(r'[ã€‚ï¼ï¼Ÿ!?]', text)
            return [s.strip() + "ã€‚" for s in sentences if s.strip()]
        else:
            # è‹±æ–‡åˆ†å¥
            import re
            sentences = re.split(r'[.!?]', text)
            return [s.strip() + "." for s in sentences if s.strip()]

    # ================== å†å²ç®¡ç† ==================

    async def process_new_component(self, component_info: Dict[str, Any],
                                    target_language: str = "zh-CN") -> Dict[str, Any]:
        """
        å¤„ç†æ–°éƒ¨ä»¶ï¼Œç”Ÿæˆæ™ºèƒ½è®²è§£

        Returns:
            åŒ…å«è¡”æ¥ã€è®²è§£å’Œå†å²ä¿¡æ¯çš„å®Œæ•´ç»“æœ
        """
        component_name = component_info.get('label', '')

        # 1. ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½è¡”æ¥å’Œè®²è§£
        transition, narrative = await self.generate_intelligent_transition(
            component_info, target_language
        )

        # 2. æ›´æ–°å†å²
        history_entry = {
            'component': component_name,
            'narrative': narrative,
            'transition': transition,
            'timestamp': time.time(),
            'language': target_language,
            'component_info': {
                'confidence': component_info.get('confidence', 0),
                'score': component_info.get('score', 0),
                'description': component_info.get('description', '')
            }
        }

        self.conversation_history.append(history_entry)
        self.components_history.append(component_name)

        # 3. é™åˆ¶å†å²é•¿åº¦
        if len(self.conversation_history) > self.max_history:
            self.conversation_history = self.conversation_history[-self.max_history:]
            self.components_history = self.components_history[-self.max_history:]

        # 4. æ„å»ºè¿”å›ç»“æœ
        result = {
            'component': component_name,
            'transition': transition,
            'narrative': narrative,
            'full_presentation': f"{transition} {narrative}",
            'history_length': len(self.conversation_history),
            'recent_components': self.components_history[-3:] if self.components_history else [],
            'llm_generated': True,
            'timestamp': time.time()
        }

        logger.info(f"ğŸ“ å·²è®²è§£ {len(self.conversation_history)} ä¸ªéƒ¨ä»¶ï¼Œæœ€æ–°: {component_name}")

        return result

    def get_conversation_flow(self) -> str:
        """è·å–å¯¹è¯æµç¨‹æ‘˜è¦"""
        if not self.conversation_history:
            return "å¯¹è¯å°šæœªå¼€å§‹"

        flow = []
        for i, entry in enumerate(self.conversation_history[-4:]):  # æœ€è¿‘4ä¸ª
            flow.append(f"{i + 1}. {entry['component']}")

        return " â†’ ".join(flow)

    def clear_history(self) -> None:
        """æ¸…ç©ºå†å²"""
        self.conversation_history = []
        self.components_history = []
        logger.info("ğŸ”„ å¯¹è¯å†å²å·²æ¸…ç©º")

    # ================== å›é€€æ–¹æ¡ˆ ==================

    def _generate_fallback_transition(self, component_name: str) -> str:
        """LLMå¤±è´¥æ—¶çš„å›é€€è¡”æ¥"""
        transitions = [
            f"æˆ‘ä»¬æ¥ç€çœ‹çœ‹{component_name}ï¼Œè¿™ä¸ªé…ç½®å¾ˆæœ‰æ„æ€ï¼Œ",
            f"æ¥ä¸‹æ¥ä»‹ç»ä¸€ä¸‹{component_name}ï¼Œ",
            f"å†çœ‹è½¦è¾†çš„{component_name}ï¼Œ",
            f"æˆ‘ä»¬ç»§ç»­ä»‹ç»{component_name}ï¼Œ"
        ]
        import random
        return random.choice(transitions)

    # ================== éƒ¨ä»¶é€‰æ‹©ç­–ç•¥ ==================

    def select_component_to_narrate(self, detections: List[Dict[str, Any]],
                                    strategy: str = "smart") -> Optional[Dict[str, Any]]:
        """
        æ™ºèƒ½é€‰æ‹©è¦è®²è§£çš„éƒ¨ä»¶

        Args:
            detections: æ‰€æœ‰æ£€æµ‹åˆ°çš„éƒ¨ä»¶
            strategy: é€‰æ‹©ç­–ç•¥

        Returns:
            é€‰æ‹©çš„éƒ¨ä»¶
        """
        if not detections:
            return None

        if strategy == "smart":
            # æ™ºèƒ½ç­–ç•¥ï¼šé¿å…é‡å¤ï¼Œè€ƒè™‘é‡è¦æ€§
            return self._smart_selection(detections)
        elif strategy == "score":
            # æŒ‰åˆ†æ•°é€‰æ‹©
            return max(detections, key=lambda x: x.get('score', 0))
        else:
            # é»˜è®¤ï¼šç¬¬ä¸€ä¸ª
            return detections[0]

    def _smart_selection(self, detections: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """æ™ºèƒ½é€‰æ‹©ç­–ç•¥"""
        # æŒ‰åˆ†æ•°æ’åº
        sorted_dets = sorted(detections, key=lambda x: x.get('score', 0), reverse=True)

        # è·å–å·²è®²è§£çš„éƒ¨ä»¶
        narrated = set(self.components_history)

        # ä¼˜å…ˆé€‰æ‹©æœªè®²è§£è¿‡çš„é«˜åˆ†éƒ¨ä»¶
        for det in sorted_dets:
            if det.get('label', '') not in narrated:
                return det

        # å¦‚æœéƒ½è®²è§£è¿‡ï¼Œé€‰æ‹©æœ€ä¹…æ²¡è®²çš„é«˜åˆ†éƒ¨ä»¶
        # è¿™é‡Œç®€åŒ–ï¼šé€‰æ‹©åˆ†æ•°æœ€é«˜çš„
        return sorted_dets[0] if sorted_dets else None


# ================== é«˜çº§åŠŸèƒ½ï¼šå¤šéƒ¨ä»¶è¿è´¯è®²è§£ ==================
class MultiComponentNarrator:
    """å¤šéƒ¨ä»¶è¿è´¯è®²è§£ç”Ÿæˆå™¨"""

    def __init__(self, dialogue_manager: SmartDialogueManager):
        self.dialogue_manager = dialogue_manager
        self.batch_history = []  # æ‰¹æ¬¡å¤„ç†å†å²

    async def generate_coherent_presentation(self, components: List[Dict[str, Any]],
                                             target_language: str = "zh-CN") -> Dict[str, Any]:
        """
        ä¸ºå¤šä¸ªéƒ¨ä»¶ç”Ÿæˆè¿è´¯çš„è®²è§£

        Args:
            components: éƒ¨ä»¶åˆ—è¡¨
            target_language: ç›®æ ‡è¯­è¨€

        Returns:
            è¿è´¯çš„è®²è§£ç»“æœ
        """
        if not components:
            return {'success': False, 'message': 'æ²¡æœ‰éƒ¨ä»¶'}

        # 1. æ™ºèƒ½æ’åºéƒ¨ä»¶
        ordered_components = self._order_components(components)

        # 2. ä¸ºæ¯ä¸ªéƒ¨ä»¶ç”Ÿæˆè®²è§£
        narratives = []
        transitions = []

        for i, component in enumerate(ordered_components):
            # ç”Ÿæˆè®²è§£
            result = await self.dialogue_manager.process_new_component(
                component, target_language
            )

            narratives.append(result['narrative'])
            transitions.append(result['transition'])

            # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªï¼Œä¸éœ€è¦ç‰¹æ®Šå¤„ç†
            # åç»­çš„ä¼šåŸºäºå†å²è‡ªåŠ¨ç”Ÿæˆè¡”æ¥

        # 3. ç»„åˆæˆå®Œæ•´è®²è§£
        full_presentation = " ".join(narratives)

        # 4. æ·»åŠ å¼€åœºç™½å’Œç»“æŸè¯­
        enhanced_presentation = self._enhance_presentation(
            full_presentation, ordered_components, target_language
        )

        return {
            'success': True,
            'components': [comp['label'] for comp in ordered_components],
            'narratives': narratives,
            'transitions': transitions,
            'full_presentation': enhanced_presentation,
            'component_count': len(ordered_components)
        }

    def _order_components(self, components: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ™ºèƒ½æ’åºéƒ¨ä»¶"""
        # è¿™é‡Œå¯ä»¥æœ‰å¾ˆå¤šæ’åºç­–ç•¥ï¼Œæ¯”å¦‚ï¼š
        # 1. æŒ‰åˆ†æ•°ä»é«˜åˆ°ä½
        # 2. æŒ‰æ±½è½¦ç³»ç»Ÿé€»è¾‘
        # 3. æŒ‰è§†è§‰ä½ç½®

        # ç®€å•å®ç°ï¼šæŒ‰åˆ†æ•°æ’åº
        return sorted(components, key=lambda x: x.get('score', 0), reverse=True)

    def _enhance_presentation(self, presentation: str, components: List[Dict[str, Any]],
                              language: str) -> str:
        """å¢å¼ºè®²è§£ï¼Œæ·»åŠ å¼€åœºå’Œç»“æŸ"""
        component_names = [comp['label'] for comp in components]

        if language == "zh-CN":
            opening = f"è®©æˆ‘ä¸ºå¤§å®¶ä»‹ç»è¿™æ¬¾è½¦çš„å‡ ä¸ªäº®ç‚¹é…ç½®ï¼ŒåŒ…æ‹¬{self._join_names(component_names)}ã€‚"
            closing = "ä»è¿™äº›é…ç½®å¯ä»¥çœ‹å‡ºï¼Œè¿™æ¬¾è½¦åœ¨è®¾è®¡ä¸Šéå¸¸ç”¨å¿ƒã€‚"
        else:
            opening = f"Let me introduce several highlight features of this vehicle, including {self._join_names(component_names, english=True)}."
            closing = "These features show the careful design of this vehicle."

        return f"{opening} {presentation} {closing}"

    def _join_names(self, names: List[str], english: bool = False) -> str:
        """è¿æ¥éƒ¨ä»¶åç§°"""
        if not names:
            return ""

        if len(names) == 1:
            return names[0]

        if english:
            if len(names) == 2:
                return f"{names[0]} and {names[1]}"
            return f"{', '.join(names[:-1])}, and {names[-1]}"
        else:
            if len(names) == 2:
                return f"{names[0]}å’Œ{names[1]}"
            return f"{'ã€'.join(names[:-1])}å’Œ{names[-1]}"


# ================== å…¨å±€å®ä¾‹ ==================

_global_smart_manager = None


def get_smart_dialogue_manager(llm_client=None) -> SmartDialogueManager:
    """è·å–æ™ºèƒ½å¯¹è¯ç®¡ç†å™¨"""
    global _global_smart_manager

    if _global_smart_manager is None:
        _global_smart_manager = SmartDialogueManager(llm_client=llm_client)

    return _global_smart_manager


def get_multi_narrator(llm_client=None) -> MultiComponentNarrator:
    """è·å–å¤šéƒ¨ä»¶è®²è§£å™¨"""
    manager = get_smart_dialogue_manager(llm_client)
    return MultiComponentNarrator(manager)


# ================== æµ‹è¯•ä»£ç  ==================

async def test_smart_dialogue():
    """æµ‹è¯•æ™ºèƒ½å¯¹è¯ç®¡ç†å™¨"""

    # æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯
    class MockLLMClient:
        async def generate_summary(self, context, target_language, question=None):
            # æ¨¡æ‹ŸLLMç”Ÿæˆè‡ªç„¶çš„è¡”æ¥
            if "å‘åŠ¨æœº" in context:
                return "åˆšæ‰æˆ‘ä»¬çœ‹äº†å¤–è§‚ï¼Œç°åœ¨æ¥çœ‹çœ‹è½¦è¾†çš„å¿ƒè„â€”â€”å‘åŠ¨æœºã€‚è¿™æ¬¾2.0Tæ¶¡è½®å¢å‹å‘åŠ¨æœºçœŸçš„å¾ˆç»™åŠ›ï¼"
            elif "å˜é€Ÿç®±" in context:
                return "æœ‰äº†å¼ºåŠ²çš„å‘åŠ¨æœºï¼Œå½“ç„¶éœ€è¦ä¸€å°èªæ˜çš„å˜é€Ÿç®±æ¥åŒ¹é…ã€‚è¿™å°7é€ŸåŒç¦»åˆå˜é€Ÿç®±æ¢æŒ¡ç‰¹åˆ«å¹³é¡ºã€‚"
            else:
                return "æˆ‘ä»¬å†æ¥çœ‹çœ‹è¿™ä¸ªé…ç½®ï¼Œå®ƒè®¾è®¡å¾—å¾ˆä¸é”™ã€‚"

    # åˆ›å»ºç®¡ç†å™¨
    manager = SmartDialogueManager(llm_client=MockLLMClient())

    # æ¨¡æ‹Ÿéƒ¨ä»¶
    engine = {
        'label': 'å‘åŠ¨æœº',
        'description': '2.0Tæ¶¡è½®å¢å‹å‘åŠ¨æœºï¼Œæœ€å¤§åŠŸç‡150kW',
        'confidence': 0.95,
        'score': 92.5
    }

    transmission = {
        'label': 'å˜é€Ÿç®±',
        'description': '7é€ŸåŒç¦»åˆå˜é€Ÿç®±ï¼Œæ¢æŒ¡è¿…é€Ÿå¹³é¡º',
        'confidence': 0.92,
        'score': 88.3
    }

    # å¤„ç†ç¬¬ä¸€ä¸ªéƒ¨ä»¶
    result1 = await manager.process_new_component(engine, "zh-CN")
    print("ç¬¬ä¸€æ¬¡è®²è§£ï¼ˆå‘åŠ¨æœºï¼‰ï¼š")
    print(f"  è¡”æ¥: {result1['transition'][:50]}...")
    print(f"  å†å²æµç¨‹: {manager.get_conversation_flow()}")
    print()

    # å¤„ç†ç¬¬äºŒä¸ªéƒ¨ä»¶ï¼ˆä¼šè‡ªåŠ¨åŸºäºå†å²ç”Ÿæˆè¡”æ¥ï¼‰
    result2 = await manager.process_new_component(transmission, "zh-CN")
    print("ç¬¬äºŒæ¬¡è®²è§£ï¼ˆå˜é€Ÿç®±ï¼‰ï¼š")
    print(f"  è¡”æ¥: {result2['transition'][:50]}...")
    print(f"  å†å²æµç¨‹: {manager.get_conversation_flow()}")
    print(f"  å®Œæ•´è®²è§£: {result2['full_presentation'][:100]}...")


if __name__ == "__main__":
    import asyncio

    asyncio.run(test_smart_dialogue())