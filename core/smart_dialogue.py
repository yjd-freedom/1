"""
æ™ºèƒ½å¯¹è¯æ¨¡å— - ä¸“ä¸šæ±½è½¦ç›´æ’­è§£è¯´ç‰ˆï¼ˆæ”¯æŒéƒ¨ä»¶å¤šæ¬¡ä»‹ç»ï¼‰
ä¼˜åŒ–ï¼šåŸºäºéƒ¨ä»¶ä»‹ç»æ¬¡æ•°çš„å·®å¼‚åŒ–è§£è¯´ + å…¨å±€å†å²è®°å½• + è‡ªç„¶è¡”æ¥
"""

import asyncio
import time
import logging
import re
import random
from typing import List, Dict, Any, Optional
from datetime import datetime

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger("smart_dialogue")


class SmartDialogueClient:
    """
    ä¸“ä¸šæ±½è½¦ç›´æ’­è§£è¯´å®¢æˆ·ç«¯
    æ”¯æŒåŸºäºéƒ¨ä»¶ä»‹ç»æ¬¡æ•°çš„å·®å¼‚åŒ–è§£è¯´
    """

    def __init__(self, llm_client):
        """
        åˆå§‹åŒ–ä¸“ä¸šè§£è¯´å®¢æˆ·ç«¯

        Args:
            llm_client: å·²æœ‰çš„LLMå®¢æˆ·ç«¯å®ä¾‹
        """
        self.llm_client = llm_client
        self.conversation_history: List[Dict[str, Any]] = []  # å…¨å±€å¯¹è¯å†å²è®°å½•
        self.max_history_length = 15
        self.total_parts_introduced = 0

        # ğŸ†• æ–°å¢ï¼šéƒ¨ä»¶ä»‹ç»æ¬¡æ•°è®¡æ•°å™¨
        self.part_introduction_counts = {}  # æ ¼å¼: {"æ•´è½¦": 2, "è½¦è½®": 1, "å‰ç¯": 1}

        self.conversation_templates = self._init_conversation_templates()
        self.functional_connections = self._init_functional_connections()

        logger.info("âœ… ä¸“ä¸šæ±½è½¦ç›´æ’­è§£è¯´å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆï¼ˆæ”¯æŒéƒ¨ä»¶å¤šæ¬¡ä»‹ç»ï¼‰")
        logger.info(f"ğŸ“Š æœ€å¤§å†å²è®°å½•é•¿åº¦: {self.max_history_length}")
        logger.info("ğŸ¯ æ ¸å¿ƒç‰¹æ€§ï¼šéƒ¨ä»¶ä»‹ç»æ¬¡æ•°ç»Ÿè®¡ + å·®å¼‚åŒ–è§£è¯´ + å…¨å±€å†å²è®°å½•")

    def _init_conversation_templates(self) -> Dict[str, Dict[str, str]]:
        """
        åˆå§‹åŒ–ä¸“ä¸šç›´æ’­è§£è¯´æ¨¡æ¿
        ğŸ†• ä¿®æ”¹ï¼šä¸ºä¸åŒä»‹ç»æ¬¡æ•°å‡†å¤‡ä¸åŒçš„æ¨¡æ¿

        Returns:
            è¯­è¨€ä»£ç åˆ°å¯¹è¯æ¨¡æ¿çš„æ˜ å°„å­—å…¸
        """
        # ğŸ†• æ–°å¢ï¼šæ ¹æ®ä»‹ç»æ¬¡æ•°é€‰æ‹©ä¸åŒæ¨¡æ¿
        return {
            "zh-CN": {
                "first_introduction": """ã€ä¸“ä¸šæ±½è½¦ç›´æ’­è§£è¯´å‘˜ - é¦–æ¬¡ä»‹ç»ã€‘

ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„æ±½è½¦ç›´æ’­è§£è¯´å‘˜ï¼Œæ­£åœ¨ä¸ºè§‚ä¼—è¿›è¡Œä¸€åœºè¿ç»­çš„ä¸“ä¸šè½¦è¾†éƒ¨ä»¶è§£è¯´ã€‚

ã€é‡è¦ç¦æ­¢è§„åˆ™ - å¿…é¡»ä¸¥æ ¼éµå®ˆã€‘
1. ç»å¯¹ä¸è¦é¢„æµ‹æˆ–æåŠä¸‹ä¸€ä¸ªéƒ¨ä»¶æ˜¯ä»€ä¹ˆ
2. ç»å¯¹ä¸è¦ä½¿ç”¨"ä¸‹ä¸ªéƒ¨ä»¶ï¼Œå’±ä»¬èŠèŠ..."è¿™æ ·çš„é¢„æµ‹æ€§è¯­å¥
3. ç»å¯¹ä¸è¦ä½¿ç”¨"ä¸‹ä¸€å¼ å›¾ç‰‡ï¼Œæˆ‘ä»¬ç»§ç»­..."è¿™æ ·çš„è¯­å¥
4. ç»å¯¹ä¸è¦ä½¿ç”¨"è¿™å°±æ˜¯æœ¬æ¬¡è§£è¯´çš„å†…å®¹ï¼Œæ„Ÿè°¢æ‚¨çš„å…³æ³¨ï¼"è¿™æ ·çš„ç»“æŸè¯­
5. ç›´æ’­è¿˜åœ¨æŒç»­è¿›è¡Œä¸­ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•ç±»ä¼¼ç»“æŸç›´æ’­çš„è¯­å¥

ã€ç›´æ’­å†å²å›é¡¾ï¼ˆæŒ‰ä»‹ç»é¡ºåºï¼‰ã€‘
{history_context}

ã€å½“å‰è¦è§£è¯´çš„éƒ¨ä»¶ - é¦–æ¬¡ä»‹ç»ã€‘
éƒ¨ä»¶åç§°ï¼š{current_part_name}
éƒ¨ä»¶åŸºæœ¬ä¿¡æ¯ï¼š{current_rag_result}

ã€æœ¬æ¬¡è§£è¯´ä»»åŠ¡ã€‘
åŸºäºæ•´ä¸ªç›´æ’­å†å²ï¼Œç”¨ä¸“ä¸šç›´æ’­çš„é£æ ¼é¦–æ¬¡ä»‹ç»å½“å‰éƒ¨ä»¶ã€‚

ã€è§£è¯´è§„åˆ™ - å¿…é¡»éµå®ˆã€‘

1. å¼€åœºæ–¹å¼ï¼š
   - å¦‚æœæ˜¯ä»Šå¤©è§£è¯´çš„ç¬¬1ä¸ªéƒ¨ä»¶ï¼šä½¿ç”¨"é¦–å…ˆï¼Œè®©æˆ‘ä»¬ä»...å¼€å§‹ä»Šå¤©çš„è§£è¯´ï¼"å¼€å¤´
   - å¦‚æœæ˜¯ç¬¬2ä¸ªåŠä»¥ä¸Šéƒ¨ä»¶ï¼šå¿…é¡»ä½¿ç”¨"åˆšæ‰æˆ‘ä»¬ä»‹ç»äº†...ï¼ŒåŸºäº...çš„è®¾è®¡/åŠŸèƒ½ï¼Œç°åœ¨æˆ‘ä»¬æ¥çœ‹..."çš„å¥å¼

2. å†å²å…³è” - é‡è¦ï¼
   - å¿…é¡»å¼•ç”¨å‰é¢è‡³å°‘1ä¸ªéƒ¨ä»¶çš„ä¿¡æ¯è¿›è¡Œæ‰©å±•ä»‹ç»
   - å»ºç«‹åŠŸèƒ½ã€è®¾è®¡æˆ–ä½“éªŒä¸Šçš„é€»è¾‘å…³è”

3. ç›´æ’­é£æ ¼è¦æ±‚ï¼š
   - å£è¯­åŒ–ã€äº²åˆ‡ã€æœ‰äº’åŠ¨æ„Ÿï¼Œåƒå’Œæœ‹å‹èŠå¤©
   - ä½¿ç”¨è®¾é—®å¥ä¸è§‚ä¼—äº’åŠ¨
   - é•¿åº¦ï¼š180-250å­—
   - ä»¥äº’åŠ¨é—®å¥æˆ–ä¸­æ€§æ€»ç»“ç»“å°¾

4. å†…å®¹è¦ç‚¹ï¼š
   - é‡ç‚¹ä»‹ç»è¯¥éƒ¨ä»¶çš„åŸºæœ¬ç‰¹å¾å’Œæ ¸å¿ƒåŠŸèƒ½
   - å»ºç«‹ä¸å†å²éƒ¨ä»¶çš„è”ç³»
   - ä¸é¢„æµ‹æœªæ¥çš„éƒ¨ä»¶

ç°åœ¨ï¼Œè¯·åŸºäºç›´æ’­å†å²ï¼Œå¼€å§‹ä½ çš„ä¸“ä¸šè§£è¯´ï¼""",

                "repeat_introduction": """ã€ä¸“ä¸šæ±½è½¦ç›´æ’­è§£è¯´å‘˜ - å†æ¬¡ä»‹ç»ã€‘

ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„æ±½è½¦ç›´æ’­è§£è¯´å‘˜ï¼Œæ­£åœ¨ä¸ºè§‚ä¼—è¿›è¡Œä¸€åœºè¿ç»­çš„ä¸“ä¸šè½¦è¾†éƒ¨ä»¶è§£è¯´ã€‚

ã€é‡è¦ç¦æ­¢è§„åˆ™ - å¿…é¡»ä¸¥æ ¼éµå®ˆã€‘
1. ç»å¯¹ä¸è¦é¢„æµ‹æˆ–æåŠä¸‹ä¸€ä¸ªéƒ¨ä»¶æ˜¯ä»€ä¹ˆ
2. ç»å¯¹ä¸è¦ä½¿ç”¨"ä¸‹ä¸ªéƒ¨ä»¶ï¼Œå’±ä»¬èŠèŠ..."è¿™æ ·çš„é¢„æµ‹æ€§è¯­å¥
3. ç»å¯¹ä¸è¦ä½¿ç”¨"ä¸‹ä¸€å¼ å›¾ç‰‡ï¼Œæˆ‘ä»¬ç»§ç»­..."è¿™æ ·çš„è¯­å¥
4. ç»å¯¹ä¸è¦ä½¿ç”¨"è¿™å°±æ˜¯æœ¬æ¬¡è§£è¯´çš„å†…å®¹ï¼Œæ„Ÿè°¢æ‚¨çš„å…³æ³¨ï¼"è¿™æ ·çš„ç»“æŸè¯­
5. ç›´æ’­è¿˜åœ¨æŒç»­è¿›è¡Œä¸­ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•ç±»ä¼¼ç»“æŸç›´æ’­çš„è¯­å¥

ã€ç›´æ’­å†å²å›é¡¾ï¼ˆæŒ‰ä»‹ç»é¡ºåºï¼‰ã€‘
{history_context}

ã€å½“å‰è¦è§£è¯´çš„éƒ¨ä»¶ - å†æ¬¡ä»‹ç»ã€‘
éƒ¨ä»¶åç§°ï¼š{current_part_name}
éƒ¨ä»¶åŸºæœ¬ä¿¡æ¯ï¼š{current_rag_result}
ä»‹ç»çŠ¶æ€ï¼šè¿™æ˜¯ç¬¬{introduction_count}æ¬¡ä»‹ç»è¯¥éƒ¨ä»¶

ã€å†å²ä»‹ç»å›é¡¾ã€‘
{previous_introductions}

ã€æœ¬æ¬¡è§£è¯´ä»»åŠ¡ã€‘
åŸºäºæ•´ä¸ªç›´æ’­å†å²ï¼Œç”¨ä¸“ä¸šç›´æ’­çš„é£æ ¼å†æ¬¡ä»‹ç»å½“å‰éƒ¨ä»¶ã€‚è¿™æ˜¯ç¬¬{introduction_count}æ¬¡ä»‹ç»è¯¥éƒ¨ä»¶ï¼Œéœ€è¦ä»ä¸åŒè§’åº¦æˆ–è¡¥å……ä¿¡æ¯è¿›è¡Œè§£è¯´ã€‚

ã€è§£è¯´è§„åˆ™ - å¿…é¡»éµå®ˆã€‘

1. å¼€åœºæ–¹å¼ - é‡è¦ï¼
   - ç»å¯¹ä¸èƒ½ä½¿ç”¨"é¦–å…ˆï¼Œè®©æˆ‘ä»¬ä»...å¼€å§‹"çš„å¼€å¤´
   - å¿…é¡»ä½¿ç”¨"è®©æˆ‘ä»¬å†æ¬¡èšç„¦..."ã€"åŸºäºä¹‹å‰æˆ‘ä»¬äº†è§£çš„...ï¼Œç°åœ¨è®©æˆ‘ä»¬ä»å¦ä¸€ä¸ªè§’åº¦çœ‹çœ‹..."ã€"æˆ‘ä»¬ç»§ç»­æ·±å…¥äº†è§£..."ç­‰å¥å¼
   - æ˜ç¡®è¡¨æ˜è¿™æ˜¯å†æ¬¡ä»‹ç»ï¼Œä¾‹å¦‚ï¼š"è®©æˆ‘ä»¬å†æ¬¡èšç„¦..."æˆ–"å›åˆ°...è¿™ä¸ªè¯é¢˜"

2. å†…å®¹å·®å¼‚åŒ– - å…³é”®ï¼
   - ä¸èƒ½ç®€å•é‡å¤ä¹‹å‰ä»‹ç»è¿‡çš„å†…å®¹
   - å¿…é¡»æä¾›æ–°çš„è§†è§’ã€è¡¥å……ä¿¡æ¯æˆ–æ·±å…¥åˆ†æ
   - å¯ä»¥ä»ä¸åŒåŠŸèƒ½ç‚¹ã€è®¾è®¡ç»†èŠ‚ã€ç”¨æˆ·ä½“éªŒç­‰æ–¹é¢è¿›è¡Œè¡¥å……
   - ç¤ºä¾‹ï¼šç¬¬ä¸€æ¬¡ä»‹ç»å¼ºè°ƒè®¾è®¡ï¼Œç¬¬äºŒæ¬¡å¯ä»¥å¼ºè°ƒæ€§èƒ½æˆ–å®é™…ä½“éªŒ

3. å†å²å…³è”ï¼š
   - æ—¢è¦å¼•ç”¨ä¹‹å‰å¯¹è¯¥éƒ¨ä»¶çš„ä»‹ç»ï¼Œä¹Ÿè¦å…³è”å…¶ä»–éƒ¨ä»¶
   - å¯ä»¥å¯¹æ¯”æœ¬æ¬¡ä»‹ç»ä¸ä¹‹å‰ä»‹ç»çš„ä¾§é‡ç‚¹å·®å¼‚

4. ç›´æ’­é£æ ¼è¦æ±‚ï¼š
   - å£è¯­åŒ–ã€äº²åˆ‡ã€æœ‰äº’åŠ¨æ„Ÿ
   - ä½¿ç”¨è®¾é—®å¥ä¸è§‚ä¼—äº’åŠ¨
   - é•¿åº¦ï¼š180-250å­—
   - ä»¥äº’åŠ¨é—®å¥æˆ–ä¸­æ€§æ€»ç»“ç»“å°¾

ã€è§£è¯´ç¤ºä¾‹ã€‘
ç¬¬ä¸€æ¬¡ä»‹ç»æ•´è½¦ï¼š"é¦–å…ˆï¼Œè®©æˆ‘ä»¬ä»æ•´è½¦å¼€å§‹ä»Šå¤©çš„è§£è¯´ï¼"
ç¬¬äºŒæ¬¡ä»‹ç»æ•´è½¦ï¼š"è®©æˆ‘ä»¬å†æ¬¡èšç„¦æ•´è½¦ï¼ŒåŸºäºä¹‹å‰æˆ‘ä»¬äº†è§£çš„è®¾è®¡ç†å¿µï¼Œç°åœ¨ä»æ€§èƒ½è§’åº¦è¿›ä¸€æ­¥äº†è§£..."
ç¬¬ä¸‰æ¬¡ä»‹ç»æ•´è½¦ï¼š"å›åˆ°æ•´è½¦è¿™ä¸ªè¯é¢˜ï¼Œè¿™æ¬¡æˆ‘ä»¬æ¢ä¸ªè§†è§’ï¼Œçœ‹çœ‹å®ƒåœ¨æ—¥å¸¸ä½¿ç”¨ä¸­çš„å®é™…è¡¨ç°..."

ç°åœ¨ï¼Œè¯·åŸºäºç›´æ’­å†å²å’Œä¹‹å‰çš„ä»‹ç»ï¼Œå¼€å§‹ä½ çš„ä¸“ä¸šè§£è¯´ï¼"""
            },

            "en-US": {
                "first_introduction": """ã€Professional Car Livestream Commentator - First Introductionã€‘

You are an experienced car livestream commentator.

ã€Livestream History Reviewã€‘
{history_context}

ã€Current Part to Commentate - First Introductionã€‘
Part Name: {current_part_name}
Basic Info: {current_rag_result}

ã€Commentary Taskã€‘
Based on the livestream history, introduce the current part for the first time.

ã€Commentary Rulesã€‘
- Use appropriate transitions based on part order
- Reference historical parts
- Provide interactive questions
- No predictions about future parts
- No ending phrases

Begin your commentary now!""",

                "repeat_introduction": """ã€Professional Car Livestream Commentator - Repeat Introductionã€‘

You are an experienced car livestream commentator.

ã€Livestream History Reviewã€‘
{history_context}

ã€Current Part to Commentate - Repeat Introductionã€‘
Part Name: {current_part_name}
Basic Info: {current_rag_result}
Introduction Status: This is the {introduction_count} time introducing this part

ã€Previous Introductions Reviewã€‘
{previous_introductions}

ã€Commentary Taskã€‘
Based on the livestream history, introduce the current part again. This is the {introduction_count} time introducing this part, so provide new perspectives or additional information.

ã€Commentary Rulesã€‘
- Do NOT use "First, let's begin with..." openings
- Use "Let's focus again on..." or "Building on our previous discussion of..."
- Provide different perspectives or additional information
- Do not simply repeat previous content
- Include interactive questions
- No predictions about future parts
- No ending phrases

Begin your commentary now!"""
            }
        }

    def _init_functional_connections(self) -> Dict[str, List[str]]:
        """
        åˆå§‹åŒ–éƒ¨ä»¶åŠŸèƒ½å…³è”åº“
        """
        return {
            "æ–¹å‘ç›˜": ["æ–¹å‘ç›˜çš„æ§åˆ¶éœ€è¦é€šè¿‡è½¬å‘ç³»ç»Ÿä¼ é€’åˆ°è½¦è½®", "æ–¹å‘ç›˜çš„æ‰‹æ„Ÿç›´æ¥å½±å“é©¾é©¶ä½“éªŒ"],
            "è½¦è½®": ["è½¦è½®çš„æŠ“åœ°åŠ›å½±å“æ–¹å‘ç›˜çš„æ§åˆ¶ç²¾åº¦", "è½¦è½®çš„å°ºå¯¸ä¸è½¦è¾†ç¨³å®šæ€§å¯†åˆ‡ç›¸å…³"],
            "åˆ¹è½¦ç³»ç»Ÿ": ["åˆ¹è½¦ç³»ç»Ÿä¸è½¦è½®çš„é…åˆç¡®ä¿åˆ¶åŠ¨æ•ˆæœ", "åˆ¹è½¦ç›˜çš„å¤§å°å½±å“åˆ¶åŠ¨è·ç¦»"],
            "å‘åŠ¨æœº": ["å‘åŠ¨æœºçš„åŠ¨åŠ›è¾“å‡ºéœ€è¦å˜é€Ÿç®±åˆç†åŒ¹é…", "å‘åŠ¨æœºçš„å¸ƒå±€å½±å“è½¦è¾†é‡å¿ƒ"],
            "å˜é€Ÿç®±": ["å˜é€Ÿç®±çš„æ¢æŒ¡é€»è¾‘å½±å“é©¾é©¶å¹³é¡ºæ€§", "å˜é€Ÿç®±ä¸å‘åŠ¨æœºçš„åŒ¹é…åº¦å½±å“æ²¹è€—"],
            "ä»ªè¡¨ç›˜": ["ä»ªè¡¨ç›˜æ˜¾ç¤ºçš„ä¿¡æ¯ä¸è½¦è¾†å„ç³»ç»ŸçŠ¶æ€ç›¸å…³", "ä»ªè¡¨ç›˜çš„å¸ƒå±€å½±å“é©¾é©¶ä¿¡æ¯è·å–æ•ˆç‡"],
            "ä¸­æ§å±": ["ä¸­æ§å±é›†æˆäº†è½¦è¾†å¤§éƒ¨åˆ†æ§åˆ¶åŠŸèƒ½", "ä¸­æ§å±çš„å“åº”é€Ÿåº¦å½±å“ç”¨æˆ·ä½“éªŒ"],
            "åº§æ¤…": ["åº§æ¤…çš„èˆ’é€‚æ€§ä¸é•¿é€”é©¾é©¶ç–²åŠ³åº¦ç›¸å…³", "åº§æ¤…çš„åŒ…è£¹æ€§ä¸è½¦è¾†æ“æ§æ€§ç›¸è¾…ç›¸æˆ"],
            "å¤§ç¯": ["å¤§ç¯çš„ç…§æ˜æ•ˆæœå½±å“å¤œé—´è¡Œè½¦å®‰å…¨", "å¤§ç¯çš„è®¾è®¡è¯­è¨€ä¸æ•´è½¦é€ å‹ç»Ÿä¸€"],
            "å°¾ç¯": ["å°¾ç¯çš„è®¾è®¡ä¸å‰å¤§ç¯å½¢æˆå‘¼åº”", "å°¾ç¯çš„äº®åº¦å½±å“åè½¦è¯†åˆ«åº¦"],
            "æ•´è½¦": ["æ•´è½¦çš„è®¾è®¡è¯­è¨€ä½“ç°åœ¨å„ä¸ªéƒ¨ä»¶çš„åè°ƒç»Ÿä¸€", "æ•´è½¦çš„æ€§èƒ½æ˜¯å„ä¸ªéƒ¨ä»¶ååŒå·¥ä½œçš„ç»“æœ"],
            "è½¦é—¨": ["è½¦é—¨çš„è®¾è®¡ä¸æ•´è½¦æµçº¿å‹é€ å‹ç›¸åè°ƒ", "è½¦é—¨çš„å¼€é—­æ„Ÿå—å½±å“ä½¿ç”¨ä½“éªŒ"],
            "è½¦çª—": ["è½¦çª—çš„è®¾è®¡å½±å“è½¦å†…é‡‡å…‰å’Œè§†é‡", "è½¦çª—çš„éš”éŸ³æ€§èƒ½å½±å“è½¦å†…é™è°§æ€§"],
            "å‰è„¸": ["å‰è„¸çš„è®¾è®¡ä½“ç°è½¦è¾†çš„å“ç‰Œç‰¹å¾", "å‰è„¸çš„é€ å‹å½±å“ç©ºæ°”åŠ¨åŠ›å­¦æ€§èƒ½"],
            "è½¦å°¾": ["è½¦å°¾çš„è®¾è®¡ä¸å‰è„¸å½¢æˆè§†è§‰å¹³è¡¡", "è½¦å°¾çš„é€ å‹å½±å“åæ–¹è§†é‡å’Œç©ºæ°”åŠ¨åŠ›å­¦"]
        }

    def add_to_history(self, part_name: str, part_description: str,
                       conversation_result: Optional[str] = None):
        """
        æ·»åŠ éƒ¨ä»¶ä»‹ç»åˆ°å…¨å±€å†å²è®°å½•
        ğŸ†• ä¿®æ”¹ï¼šæ›´æ–°éƒ¨ä»¶ä»‹ç»æ¬¡æ•°

        Args:
            part_name: éƒ¨ä»¶åç§°
            part_description: éƒ¨ä»¶æè¿°
            conversation_result: å¯¹è¯ç»“æœ
        """
        self.total_parts_introduced += 1

        # ğŸ†• æ›´æ–°éƒ¨ä»¶ä»‹ç»æ¬¡æ•°
        if part_name in self.part_introduction_counts:
            self.part_introduction_counts[part_name] += 1
        else:
            self.part_introduction_counts[part_name] = 1

        # è·å–å½“å‰ä»‹ç»æ¬¡æ•°
        introduction_count = self.part_introduction_counts[part_name]

        # æå–å…³é”®ç‰¹å¾
        key_features = self._extract_key_features(part_description)

        history_entry = {
            "part_number": self.total_parts_introduced,
            "part_name": part_name,
            "part_description": part_description,
            "key_features": key_features,
            "introduction_count": introduction_count,  # ğŸ†• è®°å½•è¿™æ˜¯ç¬¬å‡ æ¬¡ä»‹ç»è¯¥éƒ¨ä»¶
            "conversation_result": conversation_result or part_description,
            "timestamp": time.time(),
            "datetime": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

        self.conversation_history.append(history_entry)

        # ä¿æŒå†å²è®°å½•é•¿åº¦
        if len(self.conversation_history) > self.max_history_length:
            removed = self.conversation_history.pop(0)
            logger.debug(f"ğŸ—‘ï¸ ç§»é™¤æœ€æ—§å†å²è®°å½•ï¼ˆç¬¬{removed['part_number']}ä¸ªï¼‰: {removed['part_name']}")

        logger.info(f"ğŸ“ æ·»åŠ åˆ°å†å²ï¼ˆç¬¬{self.total_parts_introduced}ä¸ªï¼‰: {part_name}")
        logger.info(f"ğŸ“Š å½“å‰å†å²è®°å½•æ•°: {len(self.conversation_history)}")
        logger.info(f"ğŸ”¢ {part_name}çš„ä»‹ç»æ¬¡æ•°: {introduction_count}")

    def _extract_key_features(self, description: str, max_features: int = 3) -> List[str]:
        """
        ä»æè¿°ä¸­æå–å…³é”®ç‰¹å¾
        """
        features = []
        feature_keywords = [
            "è®¾è®¡", "æè´¨", "åŠŸèƒ½", "æ€§èƒ½", "å°ºå¯¸", "é¢œè‰²", "å½¢çŠ¶",
            "ç§‘æŠ€", "æ™ºèƒ½", "å®‰å…¨", "èˆ’é€‚", "è±ªå", "è¿åŠ¨", "ç»æµ",
            "å“åº”", "ç²¾å‡†", "ç¨³å®š", "é«˜æ•ˆ", "è€ç”¨", "ç¾è§‚", "å®ç”¨"
        ]

        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ!?.]', description)
        for sentence in sentences:
            if any(keyword in sentence for keyword in feature_keywords):
                simplified = sentence.strip()
                if len(simplified) > 5 and len(simplified) < 50:
                    features.append(simplified)
                    if len(features) >= max_features:
                        break

        if not features and description:
            features.append(description[:50].strip() + "...")

        return features

    def _get_previous_introductions(self, part_name: str, limit: int = 3) -> str:
        """
        è·å–è¯¥éƒ¨ä»¶ä¹‹å‰çš„ä»‹ç»è®°å½•
        ğŸ†• æ–°å¢ï¼šç”¨äºé‡å¤ä»‹ç»æ—¶æä¾›å†å²å‚è€ƒ

        Args:
            part_name: éƒ¨ä»¶åç§°
            limit: è¿”å›çš„å†å²è®°å½•æ•°é‡é™åˆ¶

        Returns:
            æ ¼å¼åŒ–çš„å†å²ä»‹ç»è®°å½•
        """
        previous_entries = []

        # ä»å†å²è®°å½•ä¸­æŸ¥æ‰¾è¯¥éƒ¨ä»¶çš„ä»‹ç»
        for entry in reversed(self.conversation_history):
            if entry['part_name'] == part_name:
                intro_count = entry.get('introduction_count', 1)
                key_features = entry.get('key_features', [])
                features_text = "ï¼›".join(key_features[:2]) if key_features else "æ— å…³é”®ç‰¹å¾è®°å½•"

                previous_entries.append(
                    f"ç¬¬{intro_count}æ¬¡ä»‹ç»: {features_text}"
                )

                if len(previous_entries) >= limit:
                    break

        if not previous_entries:
            return "è¿™æ˜¯ç¬¬ä¸€æ¬¡ä»‹ç»è¯¥éƒ¨ä»¶ï¼Œæ²¡æœ‰å†å²è®°å½•ã€‚"

        return "\n".join(previous_entries)

    def _build_history_context(self, current_part_name: str, current_part_number: int,
                               introduction_count: int) -> str:
        """
        æ„å»ºä¸°å¯Œçš„å†å²ä¸Šä¸‹æ–‡
        ğŸ†• ä¿®æ”¹ï¼šåŠ å…¥éƒ¨ä»¶ä»‹ç»æ¬¡æ•°ä¿¡æ¯

        Args:
            current_part_name: å½“å‰éƒ¨ä»¶åç§°
            current_part_number: å½“å‰éƒ¨ä»¶åºå·
            introduction_count: å½“å‰éƒ¨ä»¶çš„ä»‹ç»æ¬¡æ•°

        Returns:
            æ ¼å¼åŒ–çš„å†å²ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç¬¬ä¸€æ¬¡ä»‹ç»è¯¥éƒ¨ä»¶
        is_first_introduction = introduction_count == 1

        if not self.conversation_history:
            return "è¿™æ˜¯ç¬¬ä¸€ä¸ªä»‹ç»çš„éƒ¨ä»¶ï¼Œè¿˜æ²¡æœ‰å†å²å¯¹è¯ã€‚å¯ä»¥ç›´æ¥å¼€å§‹è§£è¯´ã€‚"

        # æ„å»ºå†å²å›é¡¾
        history_texts = []
        history_texts.append("ã€ç›´æ’­å†å²å›é¡¾ - æŒ‰ä»‹ç»é¡ºåºæ’åˆ—ã€‘")

        # æ˜¾ç¤ºæœ€è¿‘éƒ¨ä»¶çš„å†å²ï¼ˆæœ€å¤š8ä¸ªï¼‰
        display_count = min(len(self.conversation_history), 8)

        for i, entry in enumerate(self.conversation_history[-display_count:], 1):
            part_num = entry['part_number']
            part_name = entry['part_name']

            # å¦‚æœæ˜¯å½“å‰éƒ¨ä»¶ï¼Œç‰¹åˆ«æ ‡è®°
            if part_name == current_part_name:
                intro_count = entry.get('introduction_count', 1)
                part_name_display = f"{part_name}ï¼ˆå·²ä»‹ç»è¿‡{intro_count - 1}æ¬¡ï¼‰"
            else:
                part_name_display = part_name

            # è·å–å…³é”®ç‰¹å¾
            features = entry.get('key_features', [])
            if features:
                features_text = "ï¼›".join(features[:2])
                feature_desc = f"ï¼Œç‰¹ç‚¹ï¼š{features_text}"
            else:
                feature_desc = ""

            history_texts.append(
                f"{i}. ç¬¬{part_num}ä¸ªéƒ¨ä»¶ï¼š{part_name_display}{feature_desc}"
            )

        # æ·»åŠ å½“å‰éƒ¨ä»¶ä¿¡æ¯
        history_texts.append(f"\nã€å½“å‰éƒ¨ä»¶ä¿¡æ¯ã€‘")
        history_texts.append(f"- éƒ¨ä»¶åç§°ï¼š{current_part_name}")
        history_texts.append(f"- è¿™æ˜¯ç¬¬{current_part_number}ä¸ªä»‹ç»çš„éƒ¨ä»¶")
        history_texts.append(f"- è¿™æ˜¯ç¬¬{introduction_count}æ¬¡ä»‹ç»è¯¥éƒ¨ä»¶")

        if is_first_introduction:
            history_texts.append("- è¿™æ˜¯ç¬¬ä¸€æ¬¡ä»‹ç»è¯¥éƒ¨ä»¶ï¼Œè¯·å…¨é¢ä»‹ç»å…¶æ ¸å¿ƒç‰¹å¾")
        else:
            history_texts.append(f"- è¯¥éƒ¨ä»¶ä¹‹å‰å·²ç»ä»‹ç»è¿‡{introduction_count - 1}æ¬¡ï¼Œè¯·æä¾›æ–°çš„è§†è§’æˆ–è¡¥å……ä¿¡æ¯")

        # æ·»åŠ åŠŸèƒ½å…³è”æç¤º
        if current_part_name in self.functional_connections:
            connections = self.functional_connections[current_part_name]
            if connections:
                history_texts.append(f"\nã€åŠŸèƒ½å…³è”æç¤ºã€‘")
                history_texts.append(f"- {current_part_name}çš„åŠŸèƒ½å…³è”ï¼š{connections[0]}")

        history_texts.append(f"\nã€è§£è¯´æç¤ºã€‘")
        history_texts.append(f"- è¯·åŸºäºæ•´ä¸ªå†å²è¿›è¡Œè‡ªç„¶è¡”æ¥")
        history_texts.append(f"- ä¸è¦é¢„æµ‹ä¸‹ä¸€ä¸ªéƒ¨ä»¶")
        history_texts.append(f"- ä¸è¦ä½¿ç”¨ç»“æŸè¯­")

        return "\n".join(history_texts)

    def _find_historical_reference(self, current_part_name: str) -> Dict[str, Any]:
        """
        ä¸ºå½“å‰éƒ¨ä»¶æŸ¥æ‰¾æœ€ç›¸å…³å†å²éƒ¨ä»¶è¿›è¡Œå¼•ç”¨

        Args:
            current_part_name: å½“å‰éƒ¨ä»¶åç§°

        Returns:
            å¼•ç”¨ä¿¡æ¯å­—å…¸
        """
        if not self.conversation_history:
            return {"found": False}

        # ä¼˜å…ˆæŸ¥æ‰¾åŠŸèƒ½ç›¸å…³éƒ¨ä»¶ï¼ˆä½†ä¸æ˜¯å½“å‰éƒ¨ä»¶è‡ªèº«ï¼‰
        for history_entry in reversed(self.conversation_history):
            hist_part_name = history_entry['part_name']

            # è·³è¿‡å½“å‰éƒ¨ä»¶è‡ªèº«çš„å†å²è®°å½•
            if hist_part_name == current_part_name:
                continue

            # æ£€æŸ¥æ˜¯å¦åœ¨å…³è”åº“ä¸­
            if hist_part_name in self.functional_connections:
                for connection in self.functional_connections[hist_part_name]:
                    if any(keyword in connection for keyword in ["é…åˆ", "è”åŠ¨", "ç›¸å…³", "å½±å“", "ååŒ"]):
                        return {
                            "found": True,
                            "part_name": hist_part_name,
                            "part_number": history_entry['part_number'],
                            "connection": connection,
                            "features": history_entry.get('key_features', [])
                        }

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŠŸèƒ½å…³è”ï¼Œä½¿ç”¨æœ€è¿‘çš„ä¸€ä¸ªéå½“å‰éƒ¨ä»¶
        for history_entry in reversed(self.conversation_history):
            if history_entry['part_name'] != current_part_name:
                return {
                    "found": True,
                    "part_name": history_entry['part_name'],
                    "part_number": history_entry['part_number'],
                    "connection": f"åˆšæ‰ä»‹ç»çš„{history_entry['part_name']}",
                    "features": history_entry.get('key_features', [])
                }

        # å¦‚æœæ‰€æœ‰å†å²éƒ½æ˜¯å½“å‰éƒ¨ä»¶ï¼Œè¿”å›ç©º
        return {"found": False}

    async def generate_connected_description(self,
                                             current_part_name: str,
                                             current_rag_result: str,
                                             target_language: str = "zh-CN") -> str:
        """
        ç”Ÿæˆå…³è”çš„æè¿°ï¼ˆåŸºäºå…¨å±€å†å²è®°å½•ï¼‰
        ğŸ†• ä¿®æ”¹ï¼šæ ¹æ®ä»‹ç»æ¬¡æ•°é€‰æ‹©ä¸åŒæ¨¡æ¿

        Args:
            current_part_name: å½“å‰éƒ¨ä»¶åç§°
            current_rag_result: å½“å‰éƒ¨ä»¶çš„RAGç»“æœ
            target_language: ç›®æ ‡è¯­è¨€ä»£ç 

        Returns:
            ç»è¿‡å¯¹è¯è¡”æ¥å¤„ç†åçš„æœ€ç»ˆæè¿°
        """
        # è®¡ç®—å½“å‰æ˜¯ç¬¬å‡ ä¸ªéƒ¨ä»¶
        current_part_number = self.total_parts_introduced + 1

        # ğŸ†• è·å–å½“å‰éƒ¨ä»¶çš„ä»‹ç»æ¬¡æ•°ï¼ˆå½“å‰è¿˜æœªæ·»åŠ ï¼Œæ‰€ä»¥æ¬¡æ•°æ˜¯å·²ä»‹ç»è¿‡çš„æ¬¡æ•°ï¼‰
        introduction_count = self.part_introduction_counts.get(current_part_name, 0) + 1
        is_first_introduction = introduction_count == 1

        has_history = len(self.conversation_history) > 0

        logger.info(f"ğŸ¤ å¼€å§‹ä¸“ä¸šè§£è¯´: {current_part_name}")
        logger.info(f"ğŸ”¢ éƒ¨ä»¶åºå·: ç¬¬{current_part_number}ä¸ªéƒ¨ä»¶")
        logger.info(f"ğŸ“Š ä»‹ç»æ¬¡æ•°: ç¬¬{introduction_count}æ¬¡ä»‹ç»è¯¥éƒ¨ä»¶")
        logger.info(f"ğŸ“š å†å²çŠ¶æ€: {'æœ‰' if has_history else 'æ— '}å†å²è®°å½•")

        # æŸ¥æ‰¾å†å²å¼•ç”¨
        historical_ref = None
        if has_history:
            historical_ref = self._find_historical_reference(current_part_name)
            if historical_ref['found']:
                logger.info(f"ğŸ“ æ‰¾åˆ°å†å²å¼•ç”¨: {historical_ref['part_name']} (ç¬¬{historical_ref['part_number']}ä¸ªéƒ¨ä»¶)")

        # æ„å»ºå†å²ä¸Šä¸‹æ–‡ï¼ˆä¼ å…¥ä»‹ç»æ¬¡æ•°ï¼‰
        history_context = self._build_history_context(
            current_part_name, current_part_number, introduction_count
        )
        logger.debug(f"ğŸ“š å†å²ä¸Šä¸‹æ–‡ï¼ˆå‰300å­—ç¬¦ï¼‰:\n{history_context[:300]}...")

        # ğŸ†• æ ¹æ®ä»‹ç»æ¬¡æ•°é€‰æ‹©æ¨¡æ¿ç±»å‹
        if is_first_introduction:
            template_type = "first_introduction"
            logger.info(f"ğŸ“ ä½¿ç”¨æ¨¡æ¿: é¦–æ¬¡ä»‹ç»æ¨¡æ¿")
        else:
            template_type = "repeat_introduction"
            logger.info(f"ğŸ“ ä½¿ç”¨æ¨¡æ¿: é‡å¤ä»‹ç»æ¨¡æ¿ï¼ˆç¬¬{introduction_count}æ¬¡ï¼‰")

        # è·å–å¯¹è¯æ¨¡æ¿
        language_templates = self.conversation_templates.get(
            target_language,
            self.conversation_templates["zh-CN"]
        )

        template = language_templates.get(
            template_type,
            language_templates["first_introduction"]  # é»˜è®¤ä½¿ç”¨é¦–æ¬¡ä»‹ç»æ¨¡æ¿
        )

        # å¦‚æœæ˜¯é‡å¤ä»‹ç»ï¼Œè·å–ä¹‹å‰çš„ä»‹ç»è®°å½•
        previous_introductions = ""
        if not is_first_introduction:
            previous_introductions = self._get_previous_introductions(current_part_name)
            logger.debug(f"ğŸ“š ä¹‹å‰ä»‹ç»è®°å½•:\n{previous_introductions}")

        # æ ¼å¼åŒ–æç¤ºè¯
        prompt = template.format(
            history_context=history_context,
            current_part_name=current_part_name,
            current_rag_result=current_rag_result,
            introduction_count=introduction_count,
            previous_introductions=previous_introductions if not is_first_introduction else ""
        )

        logger.debug(f"ğŸ“ è§£è¯´æç¤ºè¯ï¼ˆå‰300å­—ç¬¦ï¼‰:\n{prompt[:300]}...")

        # è°ƒç”¨LLMç”Ÿæˆä¸“ä¸šè§£è¯´
        logger.info(f"ğŸ”„ è°ƒç”¨LLMç”Ÿæˆä¸“ä¸šè§£è¯´")
        dialogue_start_time = time.time()

        try:
            conversation_result = await self.llm_client.generate_summary(
                context=prompt,
                target_language=target_language
            )

            dialogue_end_time = time.time()
            dialogue_time = (dialogue_end_time - dialogue_start_time) * 1000
            logger.info(f"âœ… ä¸“ä¸šè§£è¯´ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {dialogue_time:.2f}ms")
            logger.info(f"ğŸ“ è§£è¯´ç»“æœé¢„è§ˆ: {conversation_result[:80]}...")

            # åå¤„ç†ï¼šç¡®ä¿ç¬¦åˆç›´æ’­è§£è¯´é£æ ¼
            conversation_result = self._post_process_for_professional_livestream(
                conversation_result,
                current_part_name,
                current_part_number,
                introduction_count,
                has_history,
                historical_ref
            )

        except Exception as e:
            logger.error(f"âŒ ä¸“ä¸šè§£è¯´ç”Ÿæˆå¤±è´¥: {e}")
            # å¤±è´¥æ—¶è¿”å›åŸºäºå†å²çš„å¯¹è¯
            conversation_result = self._create_professional_dialogue(
                current_part_name, current_rag_result, current_part_number,
                introduction_count, has_history, historical_ref
            )

        # æ›´æ–°å…¨å±€å†å²è®°å½•
        self.add_to_history(
            part_name=current_part_name,
            part_description=current_rag_result,
            conversation_result=conversation_result
        )

        return conversation_result

    def _post_process_for_professional_livestream(self, text: str, current_part_name: str,
                                                  current_part_number: int, introduction_count: int,
                                                  has_history: bool, historical_ref: Optional[Dict] = None) -> str:
        """
        åå¤„ç†ä¸­æ–‡è§£è¯´æ–‡æœ¬
        ğŸ†• ä¿®æ”¹ï¼šæ ¹æ®ä»‹ç»æ¬¡æ•°è¿›è¡Œä¸åŒçš„åå¤„ç†

        Args:
            text: åŸå§‹è§£è¯´æ–‡æœ¬
            current_part_name: å½“å‰éƒ¨ä»¶åç§°
            current_part_number: å½“å‰éƒ¨ä»¶åºå·
            introduction_count: å½“å‰éƒ¨ä»¶çš„ä»‹ç»æ¬¡æ•°
            has_history: æ˜¯å¦æœ‰å†å²è®°å½•
            historical_ref: å†å²å¼•ç”¨ä¿¡æ¯

        Returns:
            å¤„ç†åçš„è§£è¯´æ–‡æœ¬
        """
        if not text or len(text.strip()) < 20:
            return self._create_professional_dialogue(
                current_part_name, "", current_part_number, introduction_count, has_history, historical_ref
            )

        processed = text.strip()

        # ğŸ†• æ ¹æ®ä»‹ç»æ¬¡æ•°è¿›è¡Œä¸åŒçš„å¤„ç†
        is_first_introduction = introduction_count == 1

        # 1. æ£€æŸ¥å¼€å¤´æ˜¯å¦æ°å½“
        if not is_first_introduction and introduction_count > 1:
            # é‡å¤ä»‹ç»ï¼šç»å¯¹ä¸èƒ½ä½¿ç”¨"é¦–å…ˆ"å¼€å¤´
            if processed.startswith("é¦–å…ˆ"):
                logger.warning(f"âš ï¸ æ£€æµ‹åˆ°ä¸å½“å¼€å¤´ï¼ˆç¬¬{introduction_count}æ¬¡ä»‹ç»ä¸åº”ä½¿ç”¨'é¦–å…ˆ'ï¼‰")

                # æ„å»ºé€‚åˆé‡å¤ä»‹ç»çš„å¼€å¤´
                repeat_openings = [
                    f"è®©æˆ‘ä»¬å†æ¬¡èšç„¦{current_part_name}ï¼Œä»å¦ä¸€ä¸ªè§’åº¦æ·±å…¥äº†è§£...",
                    f"åŸºäºä¹‹å‰å¯¹{current_part_name}çš„ä»‹ç»ï¼Œç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å®ƒçš„å¦ä¸€ä¸ªé‡è¦æ–¹é¢...",
                    f"æˆ‘ä»¬ä¹‹å‰å·²ç»äº†è§£äº†{current_part_name}çš„åŸºæœ¬ç‰¹ç‚¹ï¼Œç°åœ¨è®©æˆ‘ä»¬è¿›ä¸€æ­¥æ¢ç´¢...",
                    f"å›åˆ°{current_part_name}è¿™ä¸ªè¯é¢˜ï¼Œè¿™æ¬¡æˆ‘ä»¬ä»ä¸åŒçš„è§†è§’æ¥çœ‹...",
                    f"ç»§ç»­æ·±å…¥{current_part_name}çš„ç»†èŠ‚ï¼Œè¿™æ¬¡æˆ‘ä»¬å…³æ³¨...",
                    f"è®©æˆ‘ä»¬é‡æ–°å®¡è§†{current_part_name}ï¼Œè¿™æ¬¡ä¾§é‡...",
                    f"å…³äº{current_part_name}ï¼Œæˆ‘ä»¬ä¹‹å‰äº†è§£äº†ä¸€éƒ¨åˆ†ï¼Œç°åœ¨è¡¥å……æ›´å¤šä¿¡æ¯..."
                ]

                opening = random.choice(repeat_openings)
                processed = processed[2:].lstrip("ï¼Œã€‚,. ")  # ç§»é™¤"é¦–å…ˆ"åŠå…¶åçš„æ ‡ç‚¹
                processed = opening + " " + processed
                logger.info(f"ğŸ”„ å·²æ›¿æ¢ä¸å½“å¼€å¤´ä¸ºé‡å¤ä»‹ç»çš„å¼€å¤´")

        elif is_first_introduction and has_history:
            # é¦–æ¬¡ä»‹ç»ä½†æœ‰å†å²ï¼šæ£€æŸ¥æ˜¯å¦åŒ…å«å†å²å¼•ç”¨
            history_ref_patterns = [
                r"åˆšæ‰æˆ‘ä»¬ä»‹ç»äº†",
                r"åŸºäºå‰é¢æåˆ°çš„",
                r"å»¶ç»­.*çš„è®¾è®¡",
                r"åœ¨.*çš„åŸºç¡€ä¸Š"
            ]

            has_ref = any(re.search(pattern, processed[:150]) for pattern in history_ref_patterns)

            if not has_ref and historical_ref and historical_ref['found']:
                # æ·»åŠ å†å²å¼•ç”¨
                ref_part = historical_ref['part_name']
                additions = [
                    f"åˆšæ‰æˆ‘ä»¬ä»‹ç»äº†{ref_part}ï¼ŒåŸºäºè¿™ä¸ªéƒ¨ä»¶çš„åŠŸèƒ½ç‰¹ç‚¹ï¼Œ",
                    f"å»¶ç»­å‰é¢éƒ¨ä»¶çš„è§£è¯´ï¼ŒåŸºäº{ref_part}çš„è®¾è®¡ç†å¿µï¼Œ",
                    f"åŸºäºåˆšæ‰å¯¹{ref_part}çš„è¯¦ç»†ä»‹ç»ï¼Œ"
                ]

                addition = random.choice(additions)
                processed = addition + processed
                logger.info(f"ğŸ”„ å·²æ·»åŠ å†å²å¼•ç”¨ï¼šåŸºäº{ref_part}")

        # 2. ç¡®ä¿æœ‰äº’åŠ¨é—®å¥
        if "ï¼Ÿ" not in processed and "?" not in processed:
            questions = [
                f"å¤§å®¶è§‰å¾—è¿™ä¸ª{current_part_name}çš„è®¾è®¡æ€ä¹ˆæ ·ï¼Ÿ",
                f"æƒ³è±¡ä¸€ä¸‹ï¼Œè¿™æ ·çš„{current_part_name}åœ¨å®é™…ä½¿ç”¨ä¸­ä¼šæœ‰ä»€ä¹ˆæ ·çš„ä½“éªŒï¼Ÿ",
                f"æ‚¨å¯¹è¿™æ ·çš„{current_part_name}è®¾è®¡æœ‰ä»€ä¹ˆçœ‹æ³•ï¼Ÿ",
                f"è¿™æ ·çš„{current_part_name}ï¼Œæ˜¯å¦ç¬¦åˆæ‚¨çš„æœŸå¾…ï¼Ÿ",
                f"çœ‹åˆ°è¿™é‡Œï¼Œæ‚¨å¯¹{current_part_name}æœ‰ä»€ä¹ˆæƒ³äº†è§£çš„å—ï¼Ÿ"
            ]

            sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', processed)
            if len(sentences) > 2:
                insert_index = max(1, len(sentences) - 2)
                question = random.choice(questions)
                sentences.insert(insert_index, question)
                processed = "ã€‚".join([s for s in sentences if s.strip()]) + "ã€‚"
            else:
                processed += " " + random.choice(questions)

        # 3. ç§»é™¤é¢„æµ‹æ€§è¯­å¥
        predictive_patterns = [
            r'ä¸‹ä¸ªéƒ¨ä»¶[ï¼Œã€‚ï¼,]?\s*å’±ä»¬èŠèŠ.*?ï¼',
            r'ä¸‹ä¸€å¼ å›¾ç‰‡[ï¼Œã€‚ï¼,]?\s*æˆ‘ä»¬ç»§ç»­.*?ï¼',
            r'æ¥ä¸‹æ¥æˆ‘ä»¬.*?å†…é¥°.*?',
            r'ä¸‹é¢æˆ‘ä»¬.*?å¤–è§‚.*?',
            r'å¾…ä¼šå„¿æˆ‘ä»¬.*?',
            r'ç­‰ä¸€ä¸‹æˆ‘ä»¬.*?',
            r'ç¨åæˆ‘ä»¬.*?',
            r'ä¸‹ä¸€ä¸ªéƒ¨ä»¶[ï¼Œã€‚ï¼,]?',
            r'ä¸‹ä¸ªå›¾ç‰‡[ï¼Œã€‚ï¼,]?'
        ]

        for pattern in predictive_patterns:
            processed = re.sub(pattern, '', processed)

        # 4. ç§»é™¤ç›´æ’­ç»“æŸè¯­å¥
        ending_phrases = [
            "è¿™å°±æ˜¯æœ¬æ¬¡è§£è¯´çš„å†…å®¹ï¼Œæ„Ÿè°¢æ‚¨çš„å…³æ³¨ï¼",
            "æœ¬æ¬¡ç›´æ’­åˆ°æ­¤ç»“æŸ",
            "æ„Ÿè°¢å¤§å®¶çš„è§‚çœ‹",
            "ç›´æ’­ç»“æŸ",
            "æœ¬æ¬¡è§£è¯´ç»“æŸ",
            "æ„Ÿè°¢æ‚¨çš„å…³æ³¨"
        ]

        for phrase in ending_phrases:
            if phrase in processed:
                neutral_endings = [
                    "æˆ‘ä»¬ç»§ç»­ä¸ºå¤§å®¶å¸¦æ¥ç²¾å½©è§£è¯´ï¼",
                    "è¿™å°±æ˜¯è¿™ä¸ªéƒ¨ä»¶çš„ç²¾å½©ä¹‹å¤„ï¼",
                    "è¿™æ ·çš„è®¾è®¡æ˜¯ä¸æ˜¯å¾ˆç”¨å¿ƒï¼Ÿ",
                    "æˆ‘ä»¬ç»§ç»­å‘ç°æ›´å¤šç²¾å½©ç»†èŠ‚ï¼"
                ]
                replacement = random.choice(neutral_endings)
                processed = processed.replace(phrase, replacement)
                logger.info(f"ğŸ”„ å·²æ›¿æ¢ç»“æŸè¯­: {phrase} â†’ {replacement}")

        # 5. ç¡®ä¿ç»“å°¾è‡ªç„¶
        neutral_endings = [
            "è¿™å°±æ˜¯å·¥ç¨‹ä¸è®¾è®¡çš„å®Œç¾ç»“åˆï¼",
            "å¤§å®¶æœ‰ä»€ä¹ˆæƒ³äº†è§£çš„å—ï¼Ÿ",
            "è¿™æ ·çš„è®¾è®¡ç¡®å®å¾ˆç”¨å¿ƒï¼",
            "æˆ‘ä»¬ç»§ç»­æ¢ç´¢è½¦è¾†çš„æ›´å¤šå¥¥ç§˜ï¼",
            "è¿™å°±æ˜¯ç²¾æ¹›å·¥è‰ºçš„ä½“ç°ï¼"
        ]

        current_end = processed[-20:] if len(processed) > 20 else processed
        has_good_ending = any(
            pattern in current_end for pattern in ["ï¼Ÿ", "ï¼", "æ€ä¹ˆæ ·", "å¦‚ä½•", "ä»€ä¹ˆçœ‹æ³•", "ä½“éªŒ"]
        )

        if not has_good_ending and len(processed) > 50:
            processed += " " + random.choice(neutral_endings)

        # 6. æ¸…ç†æ–‡æœ¬
        processed = re.sub(r'[ã€‚ï¼ï¼Ÿ]{2,}', 'ã€‚', processed)
        processed = re.sub(r'[,. ]{2,}', 'ï¼Œ', processed)
        processed = re.sub(r'\s+', ' ', processed)
        processed = processed.strip()

        if processed and processed[-1] not in ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?']:
            processed += 'ã€‚'

        return processed

    def _create_professional_dialogue(self, part_name: str, description: str,
                                      part_number: int, introduction_count: int,
                                      has_history: bool, historical_ref: Optional[Dict] = None) -> str:
        """
        åˆ›å»ºä¸“ä¸šçš„è§£è¯´å¯¹è¯ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        ğŸ†• ä¿®æ”¹ï¼šæ ¹æ®ä»‹ç»æ¬¡æ•°åˆ›å»ºä¸åŒçš„å¯¹è¯

        Args:
            part_name: éƒ¨ä»¶åç§°
            description: éƒ¨ä»¶æè¿°
            part_number: éƒ¨ä»¶åºå·
            introduction_count: ä»‹ç»æ¬¡æ•°
            has_history: æ˜¯å¦æœ‰å†å²è®°å½•
            historical_ref: å†å²å¼•ç”¨ä¿¡æ¯

        Returns:
            ä¸“ä¸šçš„è§£è¯´æ–‡æœ¬
        """
        # ğŸ†• æ ¹æ®ä»‹ç»æ¬¡æ•°é€‰æ‹©ä¸åŒçš„å¼€å¤´
        if introduction_count == 1:
            # ç¬¬ä¸€æ¬¡ä»‹ç»
            if part_number == 1:
                beginnings = [f"é¦–å…ˆï¼Œè®©æˆ‘ä»¬ä»ç¬¬{part_number}ä¸ªéƒ¨ä»¶{part_name}å¼€å§‹ä»Šå¤©çš„è§£è¯´ï¼"]
            else:
                beginnings = [f"ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ¥çœ‹ç¬¬{part_number}ä¸ªéƒ¨ä»¶{part_name}ã€‚"]
        else:
            # é‡å¤ä»‹ç»
            beginnings = [
                f"è®©æˆ‘ä»¬å†æ¬¡èšç„¦{part_name}ï¼Œè¿™æ˜¯ç¬¬{part_number}ä¸ªä»‹ç»çš„éƒ¨ä»¶ã€‚",
                f"å›åˆ°{part_name}è¿™ä¸ªè¯é¢˜ï¼Œè¿™æ˜¯ç¬¬{part_number}æ¬¡ä»‹ç»ã€‚",
                f"æˆ‘ä»¬ç»§ç»­æ·±å…¥äº†è§£{part_name}ï¼Œè¿™æ˜¯ç¬¬{part_number}ä¸ªéƒ¨ä»¶ã€‚"
            ]

        beginning = random.choice(beginnings)

        # ä¸­é—´éƒ¨åˆ†
        if description:
            middle = description
        else:
            middle = f"è¿™ä¸ª{part_name}ä½“ç°äº†è½¦è¾†çš„ç²¾æ¹›å·¥è‰ºå’Œè®¾è®¡ç†å¿µã€‚"

        # ç»“å°¾éƒ¨åˆ†
        endings = [
            f"å¤§å®¶è§‰å¾—è¿™ä¸ª{part_name}çš„è®¾è®¡æ€ä¹ˆæ ·ï¼Ÿ",
            f"æ‚¨å¯¹è¿™æ ·çš„{part_name}æœ‰ä»€ä¹ˆçœ‹æ³•ï¼Ÿ",
            f"æƒ³è±¡ä¸€ä¸‹ï¼Œè¿™æ ·çš„{part_name}åœ¨å®é™…ä½¿ç”¨ä¸­ä¼šæœ‰ä»€ä¹ˆæ ·çš„ä½“éªŒï¼Ÿ"
        ]

        ending = random.choice(endings)

        return f"{beginning}{middle}{ending}"

    def generate_connected_description_sync(self, current_part_name: str, current_rag_result: str,
                                            target_language: str = "zh-CN") -> str:
        """
        åŒæ­¥ç‰ˆæœ¬çš„æ™ºèƒ½å¯¹è¯ç”Ÿæˆï¼ˆé¿å…äº‹ä»¶å¾ªç¯å†²çªï¼‰

        Args:
            current_part_name: å½“å‰éƒ¨ä»¶åç§°
            current_rag_result: RAGç”Ÿæˆçš„ç»“æœ
            target_language: ç›®æ ‡è¯­è¨€ä»£ç 

        Returns:
            æ™ºèƒ½å¯¹è¯å¤„ç†åçš„æœ€ç»ˆæè¿°
        """
        import asyncio
        from concurrent.futures import ThreadPoolExecutor

        def _run_in_thread():
            """åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥ä»£ç """
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                async def _async_task():
                    return await self.generate_connected_description(
                        current_part_name=current_part_name,
                        current_rag_result=current_rag_result,
                        target_language=target_language
                    )

                return loop.run_until_complete(_async_task())
            finally:
                loop.close()

        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œ
        with ThreadPoolExecutor(max_workers=1) as executor:
            future = executor.submit(_run_in_thread)
            try:
                return future.result(timeout=45)
            except Exception as e:
                logger.error(f"âš ï¸ åŒæ­¥æ™ºèƒ½å¯¹è¯æ‰§è¡Œå¤±è´¥: {e}")
                # è¿”å›åŸºäºå†å²çš„ä¸“ä¸šå¯¹è¯
                current_part_number = self.total_parts_introduced + 1
                has_history = len(self.conversation_history) > 0
                introduction_count = self.part_introduction_counts.get(current_part_name, 0) + 1
                historical_ref = self._find_historical_reference(current_part_name) if has_history else None
                return self._create_professional_dialogue(
                    current_part_name, current_rag_result, current_part_number,
                    introduction_count, has_history, historical_ref
                )

    def clear_history(self):
        """æ¸…ç©ºå…¨å±€å†å²è®°å½•"""
        history_count = len(self.conversation_history)
        total_count = self.total_parts_introduced
        self.conversation_history.clear()
        self.total_parts_introduced = 0
        self.part_introduction_counts.clear()  # ğŸ†• æ¸…ç©ºä»‹ç»æ¬¡æ•°ç»Ÿè®¡
        logger.info(f"ğŸ§¹ å·²æ¸…ç©ºå…¨å±€å†å²è®°å½•ï¼Œæ¸…é™¤äº† {history_count} æ¡è®°å½•ï¼ˆå…±ä»‹ç»äº†{total_count}ä¸ªéƒ¨ä»¶ï¼‰")
        return {"history_cleared": history_count, "total_introduced": total_count}

    def get_history_stats(self) -> Dict[str, Any]:
        """
        è·å–å†å²ç»Ÿè®¡ä¿¡æ¯
        ğŸ†• ä¿®æ”¹ï¼šåŒ…å«éƒ¨ä»¶ä»‹ç»æ¬¡æ•°ç»Ÿè®¡

        Returns:
            å†å²ç»Ÿè®¡å­—å…¸
        """
        # è·å–æœ€è¿‘éƒ¨ä»¶åˆ—è¡¨
        recent_parts = []
        for entry in self.conversation_history[-5:]:
            intro_count = entry.get('introduction_count', 1)
            recent_parts.append({
                "part_number": entry["part_number"],
                "part_name": entry["part_name"],
                "introduction_count": intro_count,  # ğŸ†• æ·»åŠ ä»‹ç»æ¬¡æ•°
                "timestamp": entry["timestamp"],
                "datetime": entry["datetime"]
            })

        # è·å–æœ€è¿‘éƒ¨ä»¶
        recent_part = None
        if self.conversation_history:
            recent = self.conversation_history[-1]
            intro_count = recent.get('introduction_count', 1)
            recent_part = {
                "part_number": recent["part_number"],
                "name": recent["part_name"],
                "introduction_count": intro_count,  # ğŸ†• æ·»åŠ ä»‹ç»æ¬¡æ•°
                "time": recent["datetime"]
            }

        # ğŸ†• ç»Ÿè®¡ä»‹ç»æ¬¡æ•°æœ€å¤šçš„éƒ¨ä»¶
        top_parts = sorted(
            self.part_introduction_counts.items(),
            key=lambda x: x[1],
            reverse=True
        )[:5]

        stats = {
            "total_introduced": self.total_parts_introduced,
            "history_count": len(self.conversation_history),
            "max_capacity": self.max_history_length,
            "recent_parts": recent_parts,
            "recent_part": recent_part,
            "history_enabled": True,
            "global_history": True,
            "part_introduction_stats": {  # ğŸ†• æ–°å¢éƒ¨ä»¶ä»‹ç»ç»Ÿè®¡
                "unique_parts": len(self.part_introduction_counts),
                "top_introduced_parts": top_parts,
                "total_introductions": sum(self.part_introduction_counts.values())
            },

            # å…¼å®¹æ—§ç‰ˆæœ¬é”®å
            "total_entries": len(self.conversation_history),
            "parts_list": [entry["part_name"] for entry in self.conversation_history],
            "recent_part_name": recent["part_name"] if self.conversation_history else None,
        }

        return stats

    def get_full_history(self) -> List[Dict[str, Any]]:
        """
        è·å–å®Œæ•´çš„å†å²è®°å½•

        Returns:
            å®Œæ•´å†å²è®°å½•åˆ—è¡¨
        """
        return self.conversation_history.copy()

    def get_part_introduction_count(self, part_name: str) -> int:
        """
        è·å–æŒ‡å®šéƒ¨ä»¶çš„ä»‹ç»æ¬¡æ•°
        ğŸ†• æ–°å¢ï¼šå¤–éƒ¨æŸ¥è¯¢éƒ¨ä»¶ä»‹ç»æ¬¡æ•°

        Args:
            part_name: éƒ¨ä»¶åç§°

        Returns:
            ä»‹ç»æ¬¡æ•°ï¼Œ0è¡¨ç¤ºä»æœªä»‹ç»è¿‡
        """
        return self.part_introduction_counts.get(part_name, 0)


# å…¨å±€å¯¹è¯å®¢æˆ·ç«¯å®ä¾‹
dialogue_client = None


def init_dialogue_client(llm_client):
    """
    åˆå§‹åŒ–å…¨å±€å¯¹è¯å®¢æˆ·ç«¯

    Args:
        llm_client: LLMå®¢æˆ·ç«¯å®ä¾‹
    """
    global dialogue_client
    dialogue_client = SmartDialogueClient(llm_client)
    logger.info("âœ… ä¸“ä¸šæ±½è½¦ç›´æ’­è§£è¯´å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆï¼ˆæ”¯æŒéƒ¨ä»¶å¤šæ¬¡ä»‹ç»ï¼‰")
    logger.info("ğŸ¯ æ ¸å¿ƒç‰¹æ€§ï¼š")
    logger.info("  1. éƒ¨ä»¶ä»‹ç»æ¬¡æ•°ç»Ÿè®¡ï¼ˆåŒºåˆ†é¦–æ¬¡ä¸é‡å¤ä»‹ç»ï¼‰")
    logger.info("  2. å·®å¼‚åŒ–è§£è¯´æ¨¡æ¿ï¼ˆé¦–æ¬¡ä»‹ç» vs é‡å¤ä»‹ç»ï¼‰")
    logger.info("  3. å…¨å±€å†å²è®°å½•ï¼ˆç¨‹åºä¸é‡å¯å°±ä¸æ¸…ç©ºï¼‰")
    logger.info("  4. ç§»é™¤é¢„æµ‹æ€§è¯­å¥å’Œä¸é€‚å½“çš„ç»“æŸè¯­")
    logger.info("  5. åŸºäºåŠŸèƒ½çš„éƒ¨ä»¶å…³è”æ‰©å±•")
    return dialogue_client


def get_dialogue_client():
    """
    è·å–å…¨å±€å¯¹è¯å®¢æˆ·ç«¯

    Returns:
        SmartDialogueClientå®ä¾‹
    """
    global dialogue_client
    if dialogue_client is None:
        raise RuntimeError("æ™ºèƒ½å¯¹è¯å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ init_dialogue_client()")
    return dialogue_client